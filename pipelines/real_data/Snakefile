"""
A general framework for analysing two population migration with smcsmc.

This pipeline implements the majority of the analyses on
SGDP and HGDP samples in the article. See the README.md 
for a full description of the relevant rules and their 
associated results in the manuscript.
"""
import smcsmc
import smcsmc.utils
import os
import numpy as np
from pathlib import Path

# Chose a configuration file from the analyses
# subdirectory. This file describes the samples
# to be analysed, as well as parameters for the
# analysis. For convenience, segment files used in 
# this paper have been precomputed and included
configfile: "analyses/whole_sgdp.json"

'''
** Part 1: smcsmc

The following targets run a simple two population
SMCSMC analysis with a given initialization model 
as described in Supplemental Section 1.1.

Before running any of the following, please install
the conda environment which includes (cruciall) smc2
and msmc(2)/-IM.

Main target rules:
	- all
'''
source = [pop for pop in config["source"].keys()]
sink_segs = [pop for pop in config["sink_segs"].keys()]
replicates = config["replicates"]
sink = [pop for pop in config["sink"].keys()]
both_dict = {**config["source"], **config["sink"]}
both = source + sink
env = os.getenv("CONDA_PREFIX")
EM = int(config["EM"])
Np = int(config["Np"])
name = config["name"]

# Use your own R here.
Rpath = "~/R/bin/Rscript"


# This seed is ONLY used for the folder structure 
# construction, not in any analyses.
np.random.seed(config["seed"])
seeds_array = np.random.random_integers(1,2**31,replicates)

# Switch the comments to analyse 
# SGDP or HGDP respectively. 
#
# They require different wildcard
# constraints because the sample IDs
# are different.
''' SGDP '''
wildcard_constraints:
	seeds="\d+",
	si="[S|B]_\w+-\d+",
	sj="[S|B]_\w+-\d+",
	sa="[S|B]_\w+-\d+",
	chr="\d+"

''' HGDP 
wildcard_constraints:
	si="HGDP\d{5}",
	sj="HGDP\d{5}",
	chr="\d+"
'''

# Create segment files from VCF. This rule assumes 
# consistently named files seperated by database.
#
# i.e. HGDP/chr1.vcf.gz
# i.e. SGDP/chr7.vcf.gz
#
# Instead of preprocessing data, we have provided segment
# files for these datasets instead. All analyses can be run 
# from these files without any need for modification.
rule make_seg:
	input:
	output: seg = "segs/{seeds}/{si}.{sj}.chr{chr}.seg.gz"
	message: "Generating the seg files for {wildcards.si} and {wildcards.sj} analysis."	
	run:
		smcsmc.vcf_to_seg(
			input = [
				(config["source"][wildcards.si]+'/chr'+wildcards.chr+'.vcf.gz', wildcards.si),
				(config["sink"][wildcards.sj]+'/chr'+wildcards.chr+'.vcf.gz', wildcards.sj)],
			masks = [
				config["source"][wildcards.si]+"/mask/chr"+wildcards.chr+".bed.gz",
				config["sink"][wildcards.sj]+"/mask/chr"+wildcards.chr+".bed.gz"],
			key=wildcards.si+wildcards.sj,
			output=output.seg,
			chroms = [int(wildcards.chr)])

# Run SMC2. 
#
# Requires the conda environment to 
# be installed. See the supplemental 
# material for a rational for the arguements 
# and citations for the chosen parameters 
# (mutation, recombination rate, Ne, and 
# generation time).
#
# NOTE: If you are not using a cluster system
# 	(here QSUB is assumed), remove the
#	-c flag to run chunks sequentially. 
# 
#	See the documentation on how to run 
# 	using multiple threads.
rule smc2cli:
	input: expand("segs/1791095846/{{si}}.{{sj}}.chr{chr}.seg.gz", chr = range(1,23))
	output: "output/{name}/{seeds}/{si}.{sj}/result.out"
	message: "Starting SMC2 particle filtering."
	threads: 9
	shell: 	
		"""
		smc2 -c -chunks 100 -no_infer_recomb -nsam 4 -mu 1.25e-8 -rho 3e-9 -calibrate_lag 1.0 -EM {EM} -tmax 3.5 -alpha 0.0 -apf 2 -Np {Np} -VB -N0 14312 -I 2 2 2 -ej 0.2324 2 1 -eM 0 1 -eN 0.0 6 -eN 0.0037 4.4 -eN 0.0046 3 -eN 0.0058 2 -eN 0.0073 1.4 -eN 0.0092 0.85 -eN 0.093 1.2 -eN 0.12 1.7 -eN 0.15 2.2 -eN 0.19 2.5 -eN 0.24 2.4 -eN 0.30 2.0 -eN 0.37 1.7 -eN 0.47 1.4 -eN 0.59 1.2 -eN 0.74 1.0 -eN 0.93 0.91 -eN 1.2 1.6 -P 133 133016 31*1 -o output/{name}/{wildcards.seeds}/{wildcards.si}.{wildcards.sj} -segs segs/1791095846/{wildcards.si}.{wildcards.sj}.chr*.seg.gz -smcsmcpath ~/repos/smcsmc_older_version/smcsmc 
		"""

# Rename output files.
localrules: mv_out
rule mv_out:
	input: result = "output/{name}/{seeds}/{si}.{sj}/result.out"
	output: result = "results/{name}/{seeds}.{si}.{sj}.out"
	shell: 
		"""
		cp {input.result} {output.result}
		"""
# TARGET RULE: Perform all SMC2 analyses for
# a configuration file.
rule all:
	input: expand("results/{name}/{seeds}.{si}.{sj}.out", si = source, sj = sink, name = name, seeds=seeds_array)

'''
** Part 2: Segments and D statistics

Uses the ancestral recombination graph from above to calculate
segments containing a migration event in a specified period.

Haplotypes use bitflags, see the documentation for details. 

Main target rules:
	- run_segments
'''

# Find segments.
# 
# This setup assumes that the population of interest 
# is the second population in the segment files. 
rule segments:
	input: result = "output/{name}/{seeds}/{si}.{sj}/result.out"
	output: segments = "output/{name}/segments/{seeds}/{si}.{sj}.bed"
	message: "Calculting back-migrated segments."
	run: 
		path = "output/" + wildcards.name + "/" + wildcards.seeds + "/" + wildcards.si + "." + wildcards.sj + "/emiter10/"
		segment_path = "output/" + wildcards.name + "/segments/" + wildcards.seeds + "/" + wildcards.si + "." + wildcards.sj + ".bed"
		segs = smcsmc.utils.find_segments(path, frm=1,to=0,time_range= (1000,2500),hap=12)
		segs.to_csv(segment_path, sep = "\t", index = False)

# TARGET RULE: Create segments.
rule run_segments:
	input: expand("output/{name}/segments/{seeds}/{si}.{sj}.bed", name = name, si = source, sj = sink_segs, seeds = seeds_array[0])



# Compute D statistics.
#
# Rules:
#	- statistics: Whole Reich dataset (change the paths here)
#	- statistics_f: f3 statistics with Reich panel (change paths)
#	- run_stats / run_stats_f: Target rules.
#	- test_stats: Test rule (just make sure things are working).
comparison_population = "S_Han-1"
rule statistics:
	input: 	bed="output/{name}/segments/{seeds}/" + comparison_population + ".{sj}.bed",
		ind="/well/gerton/ccole/reich-eigenstrat/v37.2.1240K_HumanOrigins.ind"
	output: dummy=touch("output/{name}/segments/{seeds}/.tmp/{sj}.{n}.done")
	script: "r/reich.R"

rule statistics_f:
	input: 	bed="output/{name}/segments/{seeds}/" + comparison_population + ".{sj}.bed",
		ind="/well/gerton/ccole/reich-eigenstrat/v37.2.1240K_HumanOrigins.ind"
	output: dummy=touch("output/{name}/segments/{seeds}/.tmpf3/{sj}.{n}.done")
	script: "r/f3.R"

rule run_stats:
	# The n is from counting the number of unique, 
	# non "ignore", groups in the human origins .ind file
	input: expand("output/{name}/segments/{seeds}/.tmp/{sj}.{n}.done", name = name, sj = sink_segs, seeds = seeds_array[0], n = range(1, 1379))

rule run_stats_f:
	input: expand("output/{name}/segments/{seeds}/.tmpf3/{sj}.{n}.done", name = name, sj = sink_segs, seeds = seeds_array[0], n = range(1, 1379))


rule test_stats:
	input: expand("output/{name}/segments/{seeds}/.tmp/{sj}.{n}.done", name = name, sj = sink_segs[0], seeds = seeds_array[0], n = 1)


'''
** Part 3: MSMC2 analysis.

OLD. Use the msmc2 rules below.
'''

rule segs_to_msmc:
	input: seg = "segs/{seeds}/{si}.{sj}.chr{chr}.seg.gz"
	output: msmc = "msmc/{seeds}/{si}.{sj}.chr{chr}.txt"
	params:
		script="py/smc2-to-msmc.py"
	shell:
		"""
		python {params.script} -s {input.seg} -c {wildcards.chr} -o {output.msmc}
		"""

rule run_msmc:
	input: expand("msmc/{{seeds}}/{{si}}.{{sj}}.chr{chr}.txt", chr = range(1, 23))
	output: "msmc/{name}/{seeds}/{si}.{sj}.final.txt"
	log: "msmc/{name}/{seeds}/{si}.{sj}.snakemake.log"
	run:
		input_string = " ".join(["msmc/" + str(wildcards.seeds) + 
				"/" + wildcards.si + "." + wildcards.sj + 
				".chr" + str(i) + ".txt" for i in range(1,23)])
		output_prefix = "msmc/" + wildcards.name + "/" + wildcards.seeds + "/" + wildcards.si + "." + wildcards.sj
		shell("msmc --fixedRecombination --skipAmbiguous -P 0,0,1,1 -t 8 -o {output_prefix} -i 40 {input_string}")

rule msmc:
	input: expand("msmc/{name}/{seeds}/{si}.{sj}.final.txt",name = name, seeds = seeds_array[0], si = source, sj = sink)

rule test_msmc:
	input: expand("msmc/{name}/{seeds}/{si}.{sj}.final.txt",name = name, seeds = seeds_array[0], si = source[0], sj = sink[0])


''' 
** Part 4: MSMC2 Analysis.
'''

rule run_msmc2_within1: 
	input: expand("msmc/1791095846/{{si}}.{{sj}}.chr{chr}.txt", chr = range(1, 23))
	output: "msmc2/{name}/{seeds}/{si}.{sj}.within1.final.txt"
	run: 
		input_string = " ".join(["msmc/1791095846/" + 
				wildcards.si + "." + wildcards.sj + 
				".chr" + str(i) + ".txt" for i in range(1,23)])
		output_prefix = "msmc2/" + wildcards.name + "/" + wildcards.seeds + "/" + wildcards.si + "." + wildcards.sj + ".within1"
		shell("msmc2 -I 0,1 --fixedRecombination --skipAmbiguous -t 1 -o {output_prefix} {input_string}")

rule run_msmc2_within2: 
	input: expand("msmc/1791095846/{{si}}.{{sj}}.chr{chr}.txt", chr = range(1, 23))
	output: "msmc2/{name}/{seeds}/{si}.{sj}.within2.final.txt"
	run: 
		input_string = " ".join(["msmc/1791095846/" + 
				wildcards.si + "." + wildcards.sj + 
				".chr" + str(i) + ".txt" for i in range(1,23)])
		output_prefix = "msmc2/" + wildcards.name + "/" + wildcards.seeds + "/" + wildcards.si + "." + wildcards.sj + ".within2"
		shell("msmc2 -I 2,3 --fixedRecombination --skipAmbiguous -t 1 -o {output_prefix} {input_string}")

rule run_msmc2_cross: 
	input: expand("msmc/1791095846/{{si}}.{{sj}}.chr{chr}.txt", chr = range(1, 23))
	output: "msmc2/{name}/{seeds}/{si}.{sj}.cross.final.txt"
	run: 
		input_string = " ".join(["msmc/1791095846/" + 
				wildcards.si + "." + wildcards.sj + 
				".chr" + str(i) + ".txt" for i in range(1,23)])
		output_prefix = "msmc2/" + wildcards.name + "/" + wildcards.seeds + "/" + wildcards.si + "." + wildcards.sj + ".cross"
		shell("msmc2 -I 0-2,0-3,1-2,1-3 --fixedRecombination --skipAmbiguous -t 1 -o {output_prefix} {input_string}")

rule combine_msmc2:
	input: "msmc2/{name}/{seeds}/{si}.{sj}.within1.final.txt", "msmc2/{name}/{seeds}/{si}.{sj}.within2.final.txt", "msmc2/{name}/{seeds}/{si}.{sj}.cross.final.txt"
	output: "output/msmc2/{name}/{seeds}.{si}.{sj}.combined.final.txt"
	shell: '''
	export PYTHONPATH=${{PYTHONPATH}}:py/msmc-tools/
	python ~/repos/msmc-tools/combineCrossCoal.py {input[2]} {input[0]} {input[1]} > {output[0]}
	'''

localrules: generate_im
rule generate_im:
	input: "output/msmc2/{name}/{seeds}.{si}.{sj}.combined.final.txt"
	output: "output/msmc2/{name}/{seeds}.{si}.{sj}.migration.b1_1e-08.b2_1e-06.MSMC_IM.estimates.txt"
	params: prefix = lambda w: "output/msmc2/" + w.name + "/" + w.seeds + "." + w.si + "." + w.sj + ".migration"
	shell: '''
	export PYTHONPATH=${{PYTHONPATH}}:py/MSMC-IM/
	python py/MSMC-IM/MSMC_IM.py -beta 1e-8,1e-6 -o {params.prefix} {input}
	'''

localrules: rename_im
rule rename_im:
	input: "output/msmc2/{name}/{seeds}.{si}.{sj}.migration.b1_1e-08.b2_1e-06.MSMC_IM.estimates.txt"
	output: "output/msmc2/{name}/{seeds}.{si}.{sj}.migration.txt"
	shell: "mv {input} {output}"


rule run_msmc2:
	input: expand("output/msmc2/{name}/{seeds}.{si}.{sj}.migration.txt", name = name, seeds = seeds_array, si = source, sj = sink)

rule test_msmc2:
	input: expand("output/msmc2/{name}/{seeds}.{si}.{sj}.migration.txt", name = name, seeds = seeds_array[0], si = source[0], sj = sink[0])


''' 
** Part 5: Replicates of each individual analysis. 
'''

rule make_single_seg:
	output: seg = "segs/{seeds}/{sa}.chr{chr}.seg.gz"
	message: "Generating the seg files for {wildcards.sa} individual analysis."	
	run:
		smcsmc.vcf_to_seg(
			input = [(both_dict[wildcards.sa]+'/chr'+wildcards.chr+'.vcf.gz', wildcards.sa)],
			masks =	[both_dict[wildcards.sa]+"/mask/chr"+wildcards.chr+".bed.gz"],
			key=wildcards.sa,
			output=output.seg,
			chroms = [int(wildcards.chr)])

''' This rule only draws from one seed bin, otherwise
we have issues of reading and writing, and additionally all of the
segs should be the same.'''
rule smcsmc_single:
	input: expand("segs/1791095846/{{sa}}.chr{chr}.seg.gz", chr = range(1,23))
	output: "output/{name}/{seeds}/{sa}/result.out"
	params: dir = lambda wildcards, output: os.path.dirname(str(output)),
		input = lambda wildcards: "segs/1791095846/" + wildcards.sa + ".chr*.seg.gz",
		demographic_model = "-eN 0.0 6 -eN 0.0037 4.4 -eN 0.0046 3 -eN 0.0058 2 -eN 0.0073 1.4 -eN 0.0092 0.85 -eN 0.093 1.2 -eN 0.12 1.7 -eN 0.15 2.2 -eN 0.19 2.5 -eN 0.24 2.4 -eN 0.30 2.0 -eN 0.37 1.7 -eN 0.47 1.4 -eN 0.59 1.2 -eN 0.74 1.0 -eN 0.93 0.91 -eN 1.2 1.6"
	message: "Starting SMC2 particle filtering."
	threads: 9
	shell: 	
		"""
		smc2 -c -chunks 100 -no_infer_recomb -nsam 2 -mu 1.25e-8 -rho 3e-9 -calibrate_lag 1.0 -EM {EM} -tmax 3.5 -alpha 0.0 -apf 2 -Np {Np} -VB -N0 14312 {params.demographic_model} -P 133 133016 31*1 -o {params.dir} -segs {params.input} -smcsmcpath ~/repos/smcsmc_older_version/smcsmc 
		"""

localrules: mv_single_out
rule mv_single_out:
	input: result = "output/{name}/{seeds}/{sa}/result.out"
	output: result = "results/{name}/{seeds}.{sa}.out"
	shell: 
		"""
		cp {input.result} {output.result}
		"""

rule run_singles:
	input: expand("results/{name}/{seeds}.{sa}.out", sa = both, name = name, seeds=seeds_array)

rule test_singles:
	input: expand("results/{name}/{seeds}.{sa}.out", sa = both[0], name = name, seeds=seeds_array[0])
